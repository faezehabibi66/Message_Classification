# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TkYx09Pkl29d0Y0N9Rr7-f72iCzCXW_j

# Install the packages & Importing libraries
"""

!pip  install   pandas
!pip  install   nltk 
!pip  install   numpy
!pip  install   scikit-learn 
!pip  install   Unidecode 
!pip  install   lime 
!pip  install   eli5 
!pip  install   matplotlib
!pip  install   seaborn
!pip  install   xlrd 
!pip  install   jupyter

import pandas as pd
import matplotlib.pyplot as plt

"""# Reading the training and stop words files"""

df = pd.read_csv ('training_data_tweets.csv')
sw = pd.read_csv("stopwords_german.txt", sep="\n",
                             names=["stopwords"])

df.describe()

"""# Name the columns:


1.   labels: "sentiment"
2.   given sentences as data: "sentence"



"""

df = df.rename(columns={"neutral": "sentiment", 
                   "Tainted Talents (Ateliertagebuch.) Â» Wir sind nicht allein ": "sentence"})

df.describe()

"""# **Removing stop words** 
Removing stop words from training sentences to make them more-meaningful sentences
"""

pat = r'\b(?:{})\b'.format('|'.join(sw.stopwords))
df['tweet_without_stopwords'] = df['sentence'].str.replace(pat, '')
df['tweet_without_stopwords'] = df['tweet_without_stopwords'].str.replace(r'\s+', ' ')

"""*Stopwords has been removed successfully.*

# **Split the data into two parts:**

Using sklearn

1.   training dataset (train sentence, train label)
2.   test dataset (test sentence, test label)
"""

from sklearn.model_selection import train_test_split
# Drop the nan data from data set
df = df.dropna()

sentiment_train, sentiment_test, sentence_train, sentence_test = train_test_split(df.sentiment, df.sentence, test_size=0.2)
print(sentence_train.shape, sentence_test.shape, sentiment_train.shape , sentence_test.shape)
# Make sure there is no nan data
print(sum(sentence_train.isna()*1))

"""# Fit & Training
1.   **CountVectorizer:** transform a given text into a vector on the basis of the frequency (count) of each word
2.   **RandomForestClassifier**

"""

from sklearn.feature_extraction.text import CountVectorizer
vectorizer = CountVectorizer(min_df=1)
sentence_train_CV = vectorizer.fit_transform(sentence_train).toarray()

from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier()
clf.fit(sentence_train_CV, sentiment_train)

"""*Model has been fited successfully.*

# Test our models and prediction
"""

predicted_sentiment = clf.predict(vectorizer.transform(sentence_test).toarray())

from sklearn.metrics import PrecisionRecallDisplay
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

from sklearn.metrics import classification_report
print(classification_report(sentiment_test, predicted_sentiment))


cm = confusion_matrix(sentiment_test, predicted_sentiment)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                               display_labels=clf.classes_)
disp.plot()
